# An√°lise e Modelagem de Risco de Cr√©dito

Este projeto visa desenvolver um modelo de machine learning para prever o risco de inadimpl√™ncia de clientes, otimizando a concess√£o de cr√©dito e minimizando perdas financeiras.

## 1. An√°lise e Prepara√ß√£o dos Dados

Este projeto utiliza uma vers√£o do dataset "German Credit Data", um conhecido benchmark p√∫blico para problemas de classifica√ß√£o de risco de cr√©dito. O objetivo √© construir um modelo preditivo robusto a partir das caracter√≠sticas demogr√°ficas e financeiras dos clientes.

O processo iniciou-se com a importa√ß√£o das bibliotecas e o carregamento do conjunto de dados.

-   ‚úÖ Bibliotecas importadas com sucesso!
-   üìä Vers√£o do Pandas: 2.2.2
-   üìä Dataset carregado com sucesso!
-   **Shape do dataset:** (1000, 21)
-   **Mem√≥ria utilizada:** 0.16 MB

### 1.1. Visualiza√ß√£o Inicial

As primeiras linhas do dataset:

| status\_conta | duracao\_meses | historico\_credito | proposito | valor\_credito | conta\_poupanca | tempo\_emprego | taxa\_parcela | estado\_civil | outros\_devedores | tempo\_residenci a | propriedade | idade | outros\_planos | tipo\_residencia | num\_creditos | tipo\_emprego | num\_dependentes | possui\_telefone | trabalhador\_estrangeiro | risco |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| A11 | 6 | A34 | A43 | 1169 | A65 | A75 | 4 | A93 | A101 | 4 | A121 | 67 | A143 | A152 | 2 | A173 | 1 | A192 | A201 | 0 |
| A12 | 48 | A32 | A43 | 5951 | A61 | A73 | 2 | A92 | A101 | 2 | A121 | 22 | A143 | A152 | 1 | A173 | 1 | A191 | A201 | 1 |
| A14 | 12 | A34 | A46 | 2096 | A61 | A74 | 2 | A93 | A101 | 3 | A121 | 49 | A143 | A152 | 1 | A172 | 2 | A191 | A201 | 0 |
| A11 | 42 | A32 | A42 | 7882 | A61 | A74 | 2 | A93 | A103 | 4 | A122 | 45 | A143 | A153 | 1 | A173 | 2 | A191 | A201 | 0 |
| A11 | 24 | A33 | A40 | 4870 | A61 | A73 | 3 | A93 | A101 | 4 | A124 | 53 | A143 | A153 | 2 | A173 | 2 | A191 | A201 | 1 |

### 1.2. Informa√ß√µes Estat√≠sticas e Tipos de Dados

-   ‚úÖ N√£o h√° valores ausentes no dataset!

### 1.3. An√°lise Explorat√≥ria (EDA)

A distribui√ß√£o da vari√°vel alvo (`risco`) mostra um desbalanceamento de 70% de bons pagadores (classe 0) e 30% de maus pagadores (classe 1).

![Distribui√ß√£o de Clientes por Risco](./img/1.png)

A an√°lise das distribui√ß√µes e correla√ß√µes revelou que vari√°veis como `duracao_meses` e `valor_credito` possuem correla√ß√£o positiva com o risco.

![Matriz de Correla√ß√£o](./img/3.png)

## 2. Pr√©-processamento e Feature Engineering

-   ‚úÖ **Feature Engineering conclu√≠do!**
-   ‚úÖ **Encoding conclu√≠do!**
-   üîÑ **Divis√£o dos dados:** Treino (800 amostras) e Teste (200 amostras), com estratifica√ß√£o para manter a propor√ß√£o das classes.
-   ‚úÖ **Dados normalizados com RobustScaler.**
-   ‚öñÔ∏è **Balanceamento com SMOTE:** Aplicado apenas nos dados de treino para evitar vazamento de dados (data leakage).

## 3. Modelagem e Treinamento

Foram treinados e avaliados seis algoritmos de classifica√ß√£o para identificar o de melhor performance.

### 3.1. Compara√ß√£o e Sele√ß√£o do Modelo

O **Gradient Boosting** se destacou como o modelo com o maior ROC-AUC, indicando a melhor capacidade de discrimina√ß√£o entre as classes.

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score | ROC-AUC | CV-Mean | CV-Std |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Gradient Boosting** | **0.7650** | **0.6032** | **0.6333** | **0.6179** | **0.8181** | **0.9073** | **0.0848** |
| CatBoost | 0.8100 | 0.7200 | 0.6000 | 0.6545 | 0.8152 | 0.9186 | 0.0748 |
| Logistic Regression | 0.7300 | 0.5385 | 0.7000 | 0.6087 | 0.7846 | 0.8216 | 0.0410 |
| LightGBM | 0.7500 | 0.6087 | 0.4667 | 0.5283 | 0.7825 | 0.9114 | 0.0838 |
| XGBoost | 0.7800 | 0.6538 | 0.5667 | 0.6071 | 0.7824 | 0.9073 | 0.0917 |
| Random Forest | 0.7550 | 0.6222 | 0.4667 | 0.5333 | 0.7817 | 0.9283 | 0.0695 |

![Compara√ß√£o de M√©tricas](./img/4.png)

### 3.2. An√°lise do Modelo Campe√£o: Gradient Boosting

O modelo campe√£o foi avaliado em detalhes para entender seu comportamento e os tipos de erros cometidos.

**Relat√≥rio de Classifica√ß√£o Detalhado:**

| M√©trica | Precision | Recall | F1-Score | Support |
| :--- | :--- | :--- | :--- | :--- |
| **Bom Pagador** | 0.84 | 0.82 | 0.83 | 140 |
| **Mau Pagador** | 0.60 | 0.63 | 0.62 | 60 |
| **Accuracy** | | | **0.77** | **200** |
| **Macro Avg** | 0.72 | 0.73 | 0.72 | 200 |
| **Weighted Avg** | 0.77 | 0.77 | 0.77 | 200 |


![M√©tricas do Gradient Boosting](./img/5.png)

### 3.3. Justificativa das M√©tricas

-   **ROC-AUC para Sele√ß√£o:** Devido ao desbalanceamento de classes, a acur√°cia pode ser uma m√©trica enganosa. O **ROC-AUC** foi escolhido como a principal m√©trica para sele√ß√£o de modelos, pois avalia a capacidade do classificador de distinguir entre bons e maus pagadores em todos os limiares de decis√£o.
-   **An√°lise de Erros (FN vs. FP):** Em um problema de risco de cr√©dito, o custo de um **Falso Negativo** (prever que um mau pagador ser√° bom) √© significativamente maior do que o de um **Falso Positivo** (prever que um bom pagador ser√° mau). Por isso, a an√°lise da matriz de confus√£o e a otimiza√ß√£o do threshold para equilibrar precis√£o e recall (via F1-Score) s√£o cruciais.

## 4. Interpretabilidade do Modelo (XAI)

Para entender as decis√µes do modelo, foram utilizadas t√©cnicas de Explainable AI (XAI). As features mais importantes para as predi√ß√µes foram `status_conta`, `duracao_por_idade`, e `propriedade`.

![Feature Importance](./img/6.png)
![SHAP Summary Plot](./img/7.png)

## 5. Otimiza√ß√£o e Impacto Financeiro

### 5.1. Otimiza√ß√£o do Threshold de Decis√£o

O threshold padr√£o (0.5) foi otimizado para 0.55, maximizando o F1-Score e encontrando um melhor ponto de equil√≠brio para os objetivos de neg√≥cio.

![Otimiza√ß√£o do Threshold](./img/9.png)

### 5.2. An√°lise de Impacto Financeiro

A implementa√ß√£o do modelo resulta em uma economia substancial ao reduzir o n√∫mero de empr√©stimos concedidos a clientes com alto risco de inadimpl√™ncia.

-   **Custo sem modelo (aprovar todos):** R$ 60,000.00
-   **Custo Total com Modelo:** R$ 24,900.00
-   **Economia gerada pelo modelo:** R$ 35,100.00
-   **ROI do Modelo:** 58.5%

![Compara√ß√£o de Custos](./img/10.png)

## 6. Simula√ß√£o e Score Card

Foi criado um sistema simplificado de score para simular a avalia√ß√£o de novos clientes.

![An√°lise de Score de Cr√©dito](./img/11.png)

## 7. Limita√ß√µes e Considera√ß√µes

-   **Tamanho do Dataset:** O modelo foi treinado em um conjunto de 1000 amostras. Embora seja suficiente para uma prova de conceito robusta, um ambiente de produ√ß√£o se beneficiaria de um volume de dados maior para aumentar a generaliza√ß√£o.
-   **Otimiza√ß√£o de Hiperpar√¢metros:** A an√°lise focou na compara√ß√£o de algoritmos com suas configura√ß√µes padr√£o. Uma otimiza√ß√£o detalhada (tuning) poderia extrair performance adicional do modelo campe√£o.

## 8. Resumo Executivo e Pr√≥ximos Passos

### üéØ MODELO CAMPE√ÉO: Gradient Boosting
-   **ROC-AUC Score:** 0.8181
-   **F1-Score (otimizado):** 0.6379

### üí∞ IMPACTO FINANCEIRO:
-   **Economia estimada:** R$ 35,100.00
-   **ROI do modelo:** 58.5%

### üìà PR√ìXIMOS PASSOS RECOMENDADOS:
1.  **Otimiza√ß√£o de Hiperpar√¢metros:** Realizar tuning com `GridSearchCV` ou `RandomizedSearchCV` para refinar a performance do modelo.
2.  **Interpretabilidade Individual:** Explorar SHAP force plots para explicar a decis√£o de cr√©dito para clientes espec√≠ficos.
3.  **Valida√ß√£o Robusta:** Validar o modelo em um conjunto de dados de valida√ß√£o independente (out-of-time) para uma estimativa mais fiel do desempenho em produ√ß√£o.
4.  **Monitoramento em Produ√ß√£o (MLOps):** Implementar ferramentas para acompanhar o desempenho do modelo e identificar degrada√ß√µes (model drift).
5.  **Desenvolvimento de API:** Criar uma API para integrar o modelo aos sistemas de concess√£o de cr√©dito.

---
‚úÖ **Projeto conclu√≠do!**
